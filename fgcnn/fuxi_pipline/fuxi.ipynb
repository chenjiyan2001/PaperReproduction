{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/FuxiCTR/demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 16:39:47,739 P12470 INFO {\n",
      "    \"batch_norm\": \"False\",\n",
      "    \"batch_size\": \"1\",\n",
      "    \"channels\": \"[14, 16, 18, 20]\",\n",
      "    \"data_block_size\": \"-1\",\n",
      "    \"data_root\": \"../data/\",\n",
      "    \"dataset_id\": \"taobao_tiny\",\n",
      "    \"dnn_hidden_units\": \"[128, 64]\",\n",
      "    \"embedding_dim\": \"10\",\n",
      "    \"embedding_regularizer\": \"0\",\n",
      "    \"epochs\": \"3\",\n",
      "    \"every_x_epochs\": \"1\",\n",
      "    \"feature_cols\": \"[{'name': ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation'], 'active': True, 'dtype': 'str', 'type': 'categorical'}]\",\n",
      "    \"gpu\": \"-1\",\n",
      "    \"hidden_activations\": \"relu\",\n",
      "    \"kernel_heights\": \"[7, 7, 7, 7]\",\n",
      "    \"label_col\": \"{'name': 'clk', 'dtype': <class 'float'>}\",\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"loss\": \"binary_crossentropy\",\n",
      "    \"metrics\": \"['logloss', 'AUC']\",\n",
      "    \"min_categr_count\": \"1\",\n",
      "    \"model_id\": \"FGCNN_demo\",\n",
      "    \"model_root\": \"../checkpoints/\",\n",
      "    \"monitor\": \"AUC\",\n",
      "    \"monitor_mode\": \"max\",\n",
      "    \"net_dropout\": \"0\",\n",
      "    \"net_regularizer\": \"0\",\n",
      "    \"num_workers\": \"1\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"patience\": \"2\",\n",
      "    \"pickle_feature_encoder\": \"True\",\n",
      "    \"pooling_sizes\": \"[2, 2, 2, 2]\",\n",
      "    \"recombined_channels\": \"[3, 3, 3, 3]\",\n",
      "    \"save_best_only\": \"True\",\n",
      "    \"seed\": \"2019\",\n",
      "    \"shuffle\": \"True\",\n",
      "    \"task\": \"binary_classification\",\n",
      "    \"test_data\": \"../data/tiny_data/test_sample.csv\",\n",
      "    \"train_data\": \"../data/tiny_data/train_sample.csv\",\n",
      "    \"use_hdf5\": \"True\",\n",
      "    \"valid_data\": \"../data/tiny_data/valid_sample.csv\",\n",
      "    \"verbose\": \"1\",\n",
      "    \"version\": \"pytorch\"\n",
      "}\n",
      "2022-01-17 16:39:47,741 P12470 INFO Set up feature encoder...\n",
      "2022-01-17 16:39:47,741 P12470 INFO Reading file: ../data/tiny_data/train_sample.csv\n",
      "2022-01-17 16:39:47,749 P12470 INFO Reading file: ../data/tiny_data/valid_sample.csv\n",
      "2022-01-17 16:39:47,753 P12470 INFO Reading file: ../data/tiny_data/test_sample.csv\n",
      "2022-01-17 16:39:47,758 P12470 INFO Preprocess feature columns...\n",
      "2022-01-17 16:39:47,766 P12470 INFO Fit feature encoder...\n",
      "2022-01-17 16:39:47,767 P12470 INFO Processing column: {'name': 'userid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,769 P12470 INFO Processing column: {'name': 'adgroup_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,770 P12470 INFO Processing column: {'name': 'pid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,771 P12470 INFO Processing column: {'name': 'cate_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,772 P12470 INFO Processing column: {'name': 'campaign_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,773 P12470 INFO Processing column: {'name': 'customer', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,774 P12470 INFO Processing column: {'name': 'brand', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,775 P12470 INFO Processing column: {'name': 'cms_segid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,775 P12470 INFO Processing column: {'name': 'cms_group_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,776 P12470 INFO Processing column: {'name': 'final_gender_code', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,777 P12470 INFO Processing column: {'name': 'age_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,778 P12470 INFO Processing column: {'name': 'pvalue_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,778 P12470 INFO Processing column: {'name': 'shopping_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,779 P12470 INFO Processing column: {'name': 'occupation', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-01-17 16:39:47,780 P12470 INFO Set feature index...\n",
      "2022-01-17 16:39:47,780 P12470 INFO Pickle feature_encode: ../data/taobao_tiny/feature_encoder.pkl\n",
      "2022-01-17 16:39:47,782 P12470 INFO Save feature_map to json: ../data/taobao_tiny/feature_map.json\n",
      "2022-01-17 16:39:47,783 P12470 INFO Set feature encoder done.\n",
      "2022-01-17 16:39:47,784 P12470 INFO Transform feature columns...\n",
      "2022-01-17 16:39:47,786 P12470 INFO Saving data to h5: ../data/taobao_tiny/train.h5\n",
      "2022-01-17 16:39:47,831 P12470 INFO Preprocess feature columns...\n",
      "2022-01-17 16:39:47,839 P12470 INFO Transform feature columns...\n",
      "2022-01-17 16:39:47,842 P12470 INFO Saving data to h5: ../data/taobao_tiny/valid.h5\n",
      "2022-01-17 16:39:47,899 P12470 INFO Preprocess feature columns...\n",
      "2022-01-17 16:39:47,906 P12470 INFO Transform feature columns...\n",
      "2022-01-17 16:39:47,908 P12470 INFO Saving data to h5: ../data/taobao_tiny/test.h5\n",
      "2022-01-17 16:39:47,947 P12470 INFO Transform csv data to h5 done.\n",
      "2022-01-17 16:39:47,948 P12470 INFO Loading data...\n",
      "2022-01-17 16:39:47,949 P12470 INFO Loading data from h5: ../data/taobao_tiny/train.h5\n",
      "2022-01-17 16:39:47,952 P12470 INFO Loading data from h5: ../data/taobao_tiny/valid.h5\n",
      "2022-01-17 16:39:47,953 P12470 INFO Train samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-01-17 16:39:47,954 P12470 INFO Validation samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-01-17 16:39:47,954 P12470 INFO Loading train data done.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/FuxiCTR/demo\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from fuxictr import datasets\n",
    "from fuxictr.datasets.taobao import FeatureEncoder\n",
    "from fuxictr.features import FeatureMap\n",
    "from fuxictr.utils import load_config, set_logger, print_to_json\n",
    "from fuxictr.pytorch.models import FGCNN\n",
    "from fuxictr.pytorch.torch_utils import seed_everything\n",
    "import torch\n",
    "\n",
    "feature_cols = [{'name': [\"userid\",\"adgroup_id\",\"pid\",\"cate_id\",\"campaign_id\",\"customer\",\"brand\",\"cms_segid\",\n",
    "                            \"cms_group_id\",\"final_gender_code\",\"age_level\",\"pvalue_level\",\"shopping_level\",\"occupation\"],\n",
    "                    'active': True, 'dtype': 'str', 'type': 'categorical'}]\n",
    "label_col = {'name': 'clk', 'dtype': float}\n",
    "\n",
    "params = {'model_id': 'FGCNN_demo',\n",
    "            'dataset_id': 'taobao_tiny',\n",
    "            'train_data': '../data/tiny_data/train_sample.csv',\n",
    "            'valid_data': '../data/tiny_data/valid_sample.csv',\n",
    "            'test_data': '../data/tiny_data/test_sample.csv',\n",
    "            'model_root': '../checkpoints/',\n",
    "            'data_root': '../data/',\n",
    "            'feature_cols': feature_cols,\n",
    "            'label_col': label_col,\n",
    "            'embedding_regularizer': 0,\n",
    "            'net_regularizer': 0,\n",
    "            'dnn_hidden_units': [128, 64],\n",
    "            \"channels\": [14, 16, 18, 20],\n",
    "            \"kernel_heights\": [7, 7, 7, 7],\n",
    "            'hidden_activations': \"relu\",\n",
    "            'learning_rate': 1e-3,\n",
    "            'net_dropout': 0,\n",
    "            'batch_norm': False,\n",
    "            'optimizer': 'adam',\n",
    "            'task': 'binary_classification',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'metrics': ['logloss', 'AUC'],\n",
    "            'min_categr_count': 1,\n",
    "            'embedding_dim': 10,\n",
    "            \"pooling_sizes\": [2, 2, 2, 2],\n",
    "            \"recombined_channels\": [3, 3, 3, 3],\n",
    "            'batch_size': 1,\n",
    "            'epochs': 3,\n",
    "            'shuffle': True,\n",
    "            'seed': 2019,\n",
    "            'monitor': 'AUC',\n",
    "            'monitor_mode': 'max',\n",
    "            'use_hdf5': True,\n",
    "            'pickle_feature_encoder': True,\n",
    "            'save_best_only': True,\n",
    "            'every_x_epochs': 1,\n",
    "            'patience': 2,\n",
    "            'num_workers': 1,\n",
    "            'data_block_size': -1,\n",
    "            'verbose': 1,\n",
    "            'version': 'pytorch',\n",
    "            'gpu': -1}\n",
    "\n",
    "set_logger(params)\n",
    "logging.info(print_to_json(params))\n",
    "seed_everything(seed=params['seed'])\n",
    "\n",
    "# Set feature_encoder that defines how to preprocess data\n",
    "feature_encoder = FeatureEncoder(feature_cols, \n",
    "                                    label_col, \n",
    "                                    dataset_id=params['dataset_id'], \n",
    "                                    data_root=params[\"data_root\"])\n",
    "\n",
    "# Build dataset from csv to h5\n",
    "datasets.build_dataset(feature_encoder, \n",
    "                        train_data=params[\"train_data\"], \n",
    "                        valid_data=params[\"valid_data\"], \n",
    "                        test_data=params[\"test_data\"])\n",
    "\n",
    "# Get feature_map that defines feature specs\n",
    "feature_map = feature_encoder.feature_map\n",
    "\n",
    "# Get train and validation data generator from h5\n",
    "data_dir = os.path.join(params['data_root'], params['dataset_id'])\n",
    "train_gen, valid_gen = datasets.h5_generator(feature_map, \n",
    "                                                stage='train', \n",
    "                                                train_data=os.path.join(data_dir, 'train.h5'),\n",
    "                                                valid_data=os.path.join(data_dir, 'valid.h5'),\n",
    "                                                batch_size=params['batch_size'],\n",
    "                                                shuffle=params['shuffle'])\n",
    "\n",
    "# Model initialization and fitting                                                  \n",
    "torch_model = FGCNN(feature_map, **params)\n",
    "# model.count_parameters() # print number of parameters used in model\n",
    "# model.fit_generator(train_gen, \n",
    "#                     validation_data=valid_gen, \n",
    "#                     epochs=params['epochs'],\n",
    "#                     verbose=params['verbose'])\n",
    "# model.load_weights(model.checkpoint) # reload the best checkpoint\n",
    "\n",
    "# logging.info('***** validation results *****')\n",
    "# model.evaluate_generator(valid_gen)\n",
    "\n",
    "# logging.info('***** validation results *****')\n",
    "# test_gen = datasets.h5_generator(feature_map, \n",
    "#                                     stage='test',\n",
    "#                                     test_data=os.path.join(data_dir, 'test.h5'),\n",
    "#                                     batch_size=params['batch_size'],\n",
    "#                                     shuffle=False)\n",
    "# model.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuxiCTR-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/FuxiCTR\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/FuxiCTR\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from fuxictr.pytorch.models.base_model import BaseModel\n",
    "from fuxictr.pytorch.layers import EmbeddingLayer, InnerProductLayer, MLP_Layer\n",
    "# from fuxictr.pytorch.torch_utils import set_activation\n",
    "\n",
    "class fuxi_FGCNN(BaseModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"FGCNN\", \n",
    "                 gpu=-1, \n",
    "                 task=\"binary_classification\", \n",
    "                 learning_rate=1e-3, \n",
    "                 embedding_dim=10, \n",
    "                 share_embedding=False,\n",
    "                 channels=[14, 16, 18, 20],\n",
    "                 kernel_heights=[7, 7, 7, 7],\n",
    "                 pooling_sizes=[2, 2, 2, 2],\n",
    "                 recombined_channels=[2, 2, 2, 2],\n",
    "                 conv_activation=\"Tanh\",\n",
    "                 conv_batch_norm=True,\n",
    "                 dnn_hidden_units=[128, 64],\n",
    "                 dnn_activations=\"ReLU\",\n",
    "                 dnn_batch_norm=False, \n",
    "                 embedding_regularizer=None, \n",
    "                 net_regularizer=None,\n",
    "                 net_dropout=0,\n",
    "                 **kwargs):\n",
    "        super(fuxi_FGCNN, self).__init__(feature_map, \n",
    "                                    model_id=model_id, \n",
    "                                    gpu=gpu, \n",
    "                                    embedding_regularizer=embedding_regularizer, \n",
    "                                    net_regularizer=net_regularizer,\n",
    "                                    **kwargs)\n",
    "        self.share_embedding = share_embedding\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        if not self.share_embedding:\n",
    "            self.fg_embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        num_fields = feature_map.num_fields\n",
    "        channels, kernel_heights, pooling_sizes, recombined_channels \\\n",
    "            = self.validate_input(channels, \n",
    "                                  kernel_heights, \n",
    "                                  pooling_sizes, \n",
    "                                  recombined_channels)\n",
    "        self.fgcnn_layer = FGCNN_Layer(num_fields, \n",
    "                                       embedding_dim,\n",
    "                                       channels=channels, \n",
    "                                       kernel_heights=kernel_heights, \n",
    "                                       pooling_sizes=pooling_sizes,\n",
    "                                       recombined_channels=recombined_channels,\n",
    "                                       activation=conv_activation,\n",
    "                                       batch_norm=conv_batch_norm)\n",
    "        input_dim, total_features = self.compute_input_dim(embedding_dim, \n",
    "                                                           num_fields, \n",
    "                                                           channels, \n",
    "                                                           pooling_sizes, \n",
    "                                                           recombined_channels)\n",
    "        self.inner_product_layer = InnerProductLayer(total_features, output=\"inner_product\")\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=1, \n",
    "                             hidden_units=dnn_hidden_units,\n",
    "                             hidden_activations=dnn_activations,\n",
    "                             final_activation=nn.Sigmoid(),\n",
    "                             dropout_rates=net_dropout,\n",
    "                             batch_norm=dnn_batch_norm)\n",
    "        self.compile(kwargs[\"optimizer\"], loss=kwargs[\"loss\"], lr=learning_rate)\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def compute_input_dim(self, \n",
    "                          embedding_dim, \n",
    "                          num_fields, \n",
    "                          channels, \n",
    "                          pooling_sizes, \n",
    "                          recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim, total_features\n",
    "\n",
    "    def validate_input(self, \n",
    "                       channels, \n",
    "                       kernel_heights, \n",
    "                       pooling_sizes, \n",
    "                       recombined_channels):\n",
    "        if not isinstance(kernel_heights, list):\n",
    "            kernel_heights = [kernel_heights] * len(channels)\n",
    "        if not isinstance(pooling_sizes, list):\n",
    "            pooling_sizes = [pooling_sizes] * len(channels)\n",
    "        if not isinstance(recombined_channels, list):\n",
    "            recombined_channels = [recombined_channels] * len(channels)\n",
    "        if not (len(channels) == len(kernel_heights) == len(pooling_sizes) == len(recombined_channels)):\n",
    "            raise ValueError(\"channels, kernel_heights, pooling_sizes, and recombined_channels \\\n",
    "                              should have the same length.\")\n",
    "        return channels, kernel_heights, pooling_sizes, recombined_channels\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs: [X, y]\n",
    "        \"\"\"\n",
    "        X, y = self.inputs_to_device(inputs)\n",
    "        feature_emb = self.embedding_layer(X)\n",
    "        if not self.share_embedding:\n",
    "            feature_emb2 = self.fg_embedding_layer(X)\n",
    "        else:\n",
    "            feature_emb2 = feature_emb\n",
    "        conv_in = torch.unsqueeze(feature_emb2, 1) # shape (bs, 1, field, emb)\n",
    "        # print('fg_input:', conv_in.shape)\n",
    "        new_feature_emb = self.fgcnn_layer(conv_in)\n",
    "        return new_feature_emb\n",
    "        # print('new_features:', new_feature_emb.shape)\n",
    "        combined_feature_emb = torch.cat([feature_emb, new_feature_emb], dim=1)\n",
    "        # return combined_feature_emb\n",
    "        # print('combine_input:', combined_feature_emb.shape)\n",
    "        inner_product_vec = self.inner_product_layer(combined_feature_emb)\n",
    "        # return inner_product_vec\n",
    "        # print('inner_product:', inner_product_vec.shape)\n",
    "        dense_input = torch.cat([combined_feature_emb.flatten(start_dim=1), inner_product_vec], dim=1)\n",
    "        # print('dnn_input:', dense_input.shape)\n",
    "        y_pred = self.dnn(dense_input)\n",
    "        return_dict = {\"y_true\": y, \"y_pred\": y_pred}\n",
    "        return return_dict\n",
    "\n",
    "\n",
    "class FGCNN_Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Input X: tensor of shape (batch_size, 1, num_fields, embedding_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_fields, \n",
    "                 embedding_dim,\n",
    "                 channels=[3], \n",
    "                 kernel_heights=[3], \n",
    "                 pooling_sizes=[2],\n",
    "                 recombined_channels=[2],\n",
    "                 activation=\"Tanh\",\n",
    "                 batch_norm=True):\n",
    "        super(FGCNN_Layer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.channels = [1] + channels # input channel = 1\n",
    "        input_height = num_fields\n",
    "        for i in range(1, len(self.channels)):\n",
    "            in_channel = self.channels[i - 1]\n",
    "            out_channel = self.channels[i]\n",
    "            kernel_height = kernel_heights[i - 1]\n",
    "            pooling_size = pooling_sizes[i - 1]\n",
    "            recombined_channel = recombined_channels[i - 1]\n",
    "            # print('in: %d, out: %d, kernel: %d, pool: %d, recombine: %d' % \\\n",
    "            #     (in_channel, out_channel, kernel_height, pooling_size, recombined_channel))\n",
    "            conv_list.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, \n",
    "                        kernel_size=(kernel_height, 1), \n",
    "                        padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                # nn.BatchNorm2d(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2d((pooling_size, 1), padding=(input_height % pooling_size, 0))\n",
    "            ))\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_dim * out_channel\n",
    "            output_dim = input_height * embedding_dim * recombined_channel\n",
    "            # print('in: %d, out:%d' % (input_dim, output_dim))\n",
    "            recombine_layer = nn.Sequential(nn.Linear(input_dim, output_dim),\n",
    "                                            # nn.Tanh()\n",
    "                                            )\n",
    "            recombine_list.append(recombine_layer)\n",
    "        self.conv_layers = nn.ModuleList(conv_list)\n",
    "        self.recombine_layers = nn.ModuleList(recombine_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = X\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = torch.flatten(conv_out, start_dim=1)\n",
    "            # print(i)\n",
    "            # print('\\tflatten_out:', flatten_out.shape)\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            # return recombine_out.reshape(X.size(0), -1, self.embedding_dim)\n",
    "            # print('\\trecombine_out:', recombine_out.shape)\n",
    "            new_feature_list.append(recombine_out.reshape(X.size(0), -1, self.embedding_dim))\n",
    "        return conv_out\n",
    "        new_feature_emb = torch.cat(new_feature_list, dim=1)\n",
    "        return new_feature_emb\n",
    "\n",
    "torch_model = fuxi_FGCNN(feature_map, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paddle-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "\n",
    "class paddle_FGCNN(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout):\n",
    "        '''\n",
    "        Parameters\n",
    "            sparse_num_field - \n",
    "            sparse_feature_size - \n",
    "            sparse_feature_name - \n",
    "            sparse_feature_dim - \n",
    "            conv_kernel_width - \n",
    "            conv_filters - \n",
    "            new_maps - \n",
    "            pooling_width - \n",
    "            dnn_hidden_units - \n",
    "            dnn_dropout - \n",
    "        '''\n",
    "        super(paddle_FGCNN, self).__init__()\n",
    "        self.sparse_num_field = sparse_num_field\n",
    "        self.sparse_feature_size = sparse_feature_size\n",
    "        self.sparse_feature_name = sparse_feature_name\n",
    "        self.sparse_feature_dim = sparse_feature_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.conv_kernel_width = conv_kernel_width\n",
    "        self.new_maps = new_maps\n",
    "        self.pooling_width = pooling_width\n",
    " \n",
    "        \n",
    "        self.fg_embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_fg_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.fgcnn = FGCNNLayer(self.sparse_num_field, self.sparse_feature_dim,\n",
    "                                self.conv_filters, self.conv_kernel_width, \n",
    "                                self.new_maps, self.pooling_width)\n",
    "        input_dim = self.compute_input_dim(\n",
    "            self.sparse_feature_dim,\n",
    "            self.sparse_num_field,\n",
    "            self.conv_filters,\n",
    "            self.pooling_width, \n",
    "            self.new_maps,)\n",
    "        self.dnn_input_dim = input_dim\n",
    "\n",
    "        self.dnn = DNNLayer(self.dnn_input_dim, dnn_hidden_units, dnn_dropout)\n",
    "\n",
    "        self.fc_linear = self.add_sublayer(\n",
    "            name='fc_linear',\n",
    "            sublayer=nn.Linear(in_features=dnn_hidden_units[-1], out_features=1))\n",
    "\n",
    "    def compute_input_dim(self, embedding_dim, num_fields, channels, \n",
    "                          pooling_sizes, recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = paddle.to_tensor(inputs).reshape((-1, self.sparse_num_field))\n",
    "        fg_input_list = []\n",
    "        origin_input_list = []\n",
    "        for i in range(self.sparse_num_field):\n",
    "            fg_input_list.append(\n",
    "                self.fg_embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "            origin_input_list.append(\n",
    "                self.embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "        fg_input = paddle.concat(fg_input_list, axis=1)\n",
    "        origin_input = paddle.concat(origin_input_list, axis=1)\n",
    "        new_features = self.fgcnn(fg_input)\n",
    "        return new_features\n",
    "        # print('fg_input:', fg_input.shape)\n",
    "        # print('new_features:', new_features.shape)\n",
    "        combined_input = paddle.concat([origin_input, new_features], axis=1)\n",
    "        # return combined_input\n",
    "        # print('combine_input:', combined_input.shape)\n",
    "        # inner product\n",
    "        embed_list = paddle.split(\n",
    "            x=combined_input, \n",
    "            num_or_sections=combined_input.shape[1], \n",
    "            axis=1)\n",
    "        row = []\n",
    "        col = []\n",
    "        num_inputs = len(embed_list)\n",
    "        for i in range(num_inputs - 1):\n",
    "            for j in range(i + 1, num_inputs):\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "        p = paddle.concat([embed_list[idx] for idx in row], axis=1)  # batch num_pairs k\n",
    "        q = paddle.concat([embed_list[idx] for idx in col], axis=1)\n",
    "\n",
    "        inner_product = paddle.sum(p * q, axis=2, keepdim=True)\n",
    "        inner_product = paddle.flatten(inner_product, start_axis=1)\n",
    "        # return inner_product\n",
    "        linear_signal = paddle.flatten(combined_input, start_axis=1)\n",
    "        # print('linear_signal:', linear_signal.shape)\n",
    "        # print('inner_prodcut', inner_product.shape)\n",
    "        dnn_input = paddle.concat([linear_signal, inner_product], axis=1)\n",
    "        # print('dnn_input:', dnn_input.shape)\n",
    "        dnn_output = self.dnn(dnn_input)\n",
    "        dnn_logit = self.fc_linear(dnn_output)\n",
    "        y_pred = F.sigmoid(dnn_logit)\n",
    "        return y_pred\n",
    "\n",
    "class EmbeddingLayer(nn.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, feature_name):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            name=feature_name,\n",
    "            sparse=True\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.embedding(inputs)\n",
    "    \n",
    "class FGCNNLayer(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, embedding_size, filters, kernel_width, new_maps, pooling_width):\n",
    "        super(FGCNNLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.filters = [1] + filters # input channel = 1\n",
    "        input_height = sparse_num_field\n",
    "        for i in range(1, len(self.filters)):\n",
    "            in_channel = self.filters[i - 1]\n",
    "            out_channel = self.filters[i]\n",
    "            kernel_height = kernel_width[i - 1]\n",
    "            pooling_size = pooling_width[i - 1]\n",
    "            recombined_channel = new_maps[i - 1]\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv2D(\n",
    "                    in_channels=in_channel, \n",
    "                    out_channels=out_channel, \n",
    "                    kernel_size=(kernel_height, 1), \n",
    "                    padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                # nn.BatchNorm2D(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2D(\n",
    "                    kernel_size=(pooling_size, 1), \n",
    "                    padding=(input_height % pooling_size, 0)))\n",
    "            # )\n",
    "            conv_list.append(conv_layer)\n",
    "\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_size * out_channel\n",
    "            output_dim = input_height * embedding_size * recombined_channel\n",
    "            # print('in: %d, out:%d' % (input_dim, output_dim))\n",
    "            recombine_layer = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=input_dim, \n",
    "                    out_features=output_dim), \n",
    "                # nn.Tanh()\n",
    "                )\n",
    "            recombine_list.append(recombine_layer)\n",
    "\n",
    "        self.conv_layers = nn.LayerList(conv_list)\n",
    "        self.recombine_layers = nn.LayerList(recombine_list)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        conv_out = inputs.unsqueeze(1)\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.filters) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = paddle.flatten(conv_out, start_axis=1)\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            recombine_out = recombine_out.reshape((inputs.shape[0], -1, self.embedding_size))\n",
    "            # return recombine_out\n",
    "            new_feature_list.append(recombine_out)\n",
    "        return conv_out\n",
    "        new_features = paddle.concat(new_feature_list, axis=1)\n",
    "        return new_features\n",
    "\n",
    "class DNNLayer(nn.Layer):\n",
    "    def __init__(self, inputs_dim, hidden_units, dropout_rate):\n",
    "        super(DNNLayer, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        hidden_units = [inputs_dim] + list(hidden_units)\n",
    "        self.linears = nn.LayerList([nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=hidden_units[i], \n",
    "                out_features=hidden_units[i + 1],\n",
    "                name='dnn_%d' % i),\n",
    "            # nn.BatchNorm(hidden_units[i+1])\n",
    "            ) for i in range(len(hidden_units) - 1)])\n",
    "        \n",
    "        self.activation_layers = nn.LayerList(\n",
    "            [nn.ReLU(hidden_units[i + 1]) for i in range(len(hidden_units) - 1)])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        for i in range(len(self.linears)):\n",
    "            inputs = self.linears[i](inputs)\n",
    "            inputs = self.activation_layers[i](inputs)\n",
    "            inputs = self.dropout(inputs)\n",
    "        return inputs\n",
    "\n",
    "# hyperparameters\n",
    "sparse_num_field = 14\n",
    "sparse_feature_size = [25, 95, 3, 48, 98, 97, 66, 10, 10, 3, 6, 3, 4, 3]\n",
    "sparse_feature_name = ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation']\n",
    "sparse_feature_dim = 10\n",
    "conv_kernel_width =  [7, 7, 7, 7]\n",
    "conv_filters =  [14, 16, 18, 20]\n",
    "new_maps =  [3, 3, 3, 3]\n",
    "pooling_width =  [2, 2, 2, 2]\n",
    "dnn_hidden_units =  [128, 64]\n",
    "dnn_dropout =  0.0\n",
    "paddle_model = paddle_FGCNN(sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import paddle\n",
    "# from paddle_net import FGCNN as paddle_FGCNN\n",
    "from reprod_log import ReprodLogger, ReprodDiffHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/fuxi_pipline\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "%cd ~/code/PaperReproduction/fgcnn/fuxi_pipline\n",
    "# data\n",
    "pipline_data = pickle.load(open('data/sample.pkl', 'rb'))\n",
    "# torch\n",
    "torch_para = torch.load('data/torch_para.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name map\n",
    "name_map = {k:v for k,v in enumerate(sparse_feature_name)}\n",
    "# fuxi\n",
    "torch_linear_key = \\\n",
    "    ['dnn.dnn.%d.weight' % i for i in [0, 2, 4]] + \\\n",
    "    ['dnn.dnn.%d.bias' % i for i in [0, 2, 4]] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_var' % i for i in range(4)] \n",
    "torch_other_key = \\\n",
    "    ['embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fg_embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.bias' % i for i in range(4)]      \n",
    "\n",
    "# paddle\n",
    "paddle_linear_key = \\\n",
    "    ['dnn.linears.%d.0.weight' % i for i in [0, 1]] + ['fc_linear.weight'] + \\\n",
    "    ['dnn.linears.%d.0.bias' % i for i in [0, 1]] + ['fc_linear.bias'] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._variance' % i for i in range(4)]\n",
    "paddle_other_key = \\\n",
    "    ['embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fg_embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.bias' % i for i in range(4)]\n",
    "\n",
    "# fuxi2paddle\n",
    "key_map = {key_t:key_p for key_t, key_p in zip(torch_other_key, paddle_other_key)}\n",
    "paddle_para = {key_map[k]:paddle.to_tensor(v.numpy()) for k, v in torch_para.items() if k in torch_other_key}\n",
    "for t, p in zip(torch_linear_key, paddle_linear_key):\n",
    "    if t in torch_para.keys():\n",
    "        paddle_para[p] = paddle.to_tensor(torch_para[t].T.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paddel\n",
    "p_fgcnn_layer = list(paddle_model.children())[2]\n",
    "p_recombine_layer = list(p_fgcnn_layer.children())[1]\n",
    "p_linear_layer = next(next(p_recombine_layer.children()).children())\n",
    "p_para = p_linear_layer.parameters()[0].numpy()\n",
    "# torch\n",
    "t_fgcnn_layer = list(torch_model.children())[2]\n",
    "t_recombine_layer = list(t_fgcnn_layer.children())[1]\n",
    "t_linear_layer = next(next(t_recombine_layer.children()).children())\n",
    "t_para = next(t_linear_layer.parameters()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test\n",
    "in-out:\n",
    "- origin_input: ok\n",
    "- fg_input: ok\n",
    "- fgcnn_layer:\n",
    "    - conv:\n",
    "        - conv2d: ok\n",
    "        - batchnorm2d: no\n",
    "        - tanh: no\n",
    "        - maxpool2d: ok\n",
    "    - flatten: ok\n",
    "    - recombine: no\n",
    "\n",
    "para:\n",
    "- emb: ok\n",
    "- fg_emb: ok\n",
    "- conv: ok\n",
    "- recombine: ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_para = torch_model.state_dict()\n",
    "# fuxi2paddle\n",
    "key_map = {key_t:key_p for key_t, key_p in zip(torch_other_key, paddle_other_key)}\n",
    "paddle_para = {key_map[k]:paddle.to_tensor(v.numpy()) for k, v in torch_para.items() if k in torch_other_key}\n",
    "for t, p in zip(torch_linear_key, paddle_linear_key):\n",
    "    if t in torch_para.keys():\n",
    "        paddle_para[p] = paddle.to_tensor(torch_para[t].T.numpy())\n",
    "\n",
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "\n",
    "torch_model.eval()\n",
    "paddle_model.eval()\n",
    "data, label = pipline_data[0][:-1], pipline_data[0][-1]\n",
    "# torch\n",
    "torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "# torch_out = torch_model.forward(torch_inputs)['y_pred'].detach().numpy()\n",
    "torch_out = torch_model.forward(torch_inputs).detach().numpy()\n",
    "# paddle\n",
    "paddle_out = paddle_model.forward(data).numpy()\n",
    "# diff\n",
    "diff = (torch_out - paddle_out).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEDCAYAAAAoWo9tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfoElEQVR4nO3de5AlVX0H8O9vLhe8CHEgTCk7u8uuj4wREAdGUVdjiY9BFFnBB8QkWlK1laokpRUda7eoCpiqFKtTWomVh9lEShMJKrKMRCQDBio+StBZZodlgVEQES4rjMqIZCdyd+aXP27f2Z6eft4+/Tjd308VxWxP3+7Tp8/9zb2nf/1rUVUQEZG9BopuABERpcNATkRkOQZyIiLLMZATEVmOgZyIyHIM5ERElisskIvINSLypIjca2h7nxKRgyJyv4h8VkTExHaJiMquyE/kXwBwvokNichrAWwD8HIAZwB4JYA3mNg2EVHZFRbIVfXbAH7lXiYiLxKR/xKRfSLyHRF5adzNAXgOgGMBHAegCeAJow0mIiqpss2R7wHwF6p6DoCPAfjHOC9S1e8DuAPAIee/aVW9P7NWEhGVyDFFN6BHRE4A8FoA17umt49zfncxgL/2eVlbVcdF5MUAfh/ARmf5bSLyelX9TsbNJiIqXGkCObrfDhZV9RXeX6jqXgB7Q177LgB3quozACAitwB4DQAGciKqvNJMrajq0wAeFpH3AIB0nRXz5T8D8AYROUZEmuhe6OTUChHVQpHph9cB+D6AERF5TEQuB/B+AJeLyByAgwAuirm5rwF4CMABAHMA5lT1PzNoNhFR6QjL2BIR2a00UytERNSfQi52nnLKKbply5Yidk1EZK19+/b9QlWHvMsLCeRbtmzBzMxMEbsmIrKWiDzit5xTK0RElmMgJyKyHAM5EZHlGMiJiCyXOpCLyHNE5AciMufUA/+EiYYREVE8JrJWfgvgPFV9xrk9/rsicouq3mlg20RExkzNtjE5PY/HF5ewYbCFifERbB8dLrpZqaUO5Nq9NfQZ559N5z/eLkpEpTI128auvQew1FkGALQXl7Br7wEAsD6YG5kjF5GGiOwH8CSA21T1Lp91dojIjIjMLCwsmNgtEVFsk9Pzq0G8Z6mzjMnp+YJaZI6RQK6qy0752Y0AXiUiZ/iss0dVx1R1bGho3Y1JRESZenxxKdFymxjNWlHVRXSf1GPkWZxERKZsGGwlWm4TE1krQyIy6PzcAvAWAA+k3S4RkUkT4yNoNRtrlrWaDUyMjxTUInNMZK2cCuCLItJA9w/DV1X1Gwa2S0RkTO+CJrNWfKjqPQBGDbSFiChT20eHKxG4vXhnJxGR5RjIiYgsx0BORGQ5BnIiIssxkBMRWY6BnIjIcgzkRESWYyAnIrIcAzkRkeUYyImILMdATkRkOQZyIiLLMZATEVmOgZyIyHIM5ERElmMgJyKyHAM5EZHlGMiJiCzHQE5EZDkGciIiy6V++HJdTM22K/n0bSq3qdk2rrrpIBaXOgCAk45v4soLTwdQjafBp31fBfXP9tHh1W23F5fQEMGyKoZT9FWZY4Coau47HRsb05mZmdz326+p2TZ27T2Apc7y6rJWs4GrLz6zNCeSqmdqto2J6+fQWVn7Hh0QoDEg6CwfXW7jeEz7vgrqn2ZD8L5XbsIN+9prtt3PPky11RQR2aeqY97lnFqJYXJ6ft2AWOosY3J6vqAWUR1MTs+vC1IAsKJYE8QBO8dj2vdVUP90lhXX3fWobxBPug9Tbc0aA3kMjy8uJVpOZELS8WXbeEz7vgpbbzlipsFU35alzxnIY9gw2Eq0nMiEpOPLtvGY9n0Vtl5DpO/XJlm/LH3OQB7DxPgIWs3GmmWtZgMT4yMFtYjqYGJ8BM2B9QFpQLrzwG42jse076ug/mk2BJedu2ndtvvZh6m2Zo1ZKzH0LmaU9Yo1VVNvfFU1ayXt+yqsf7aPDmPstJONZa2UPQYwa4WIyBLMWiEiqqjUgVxENonIHSJyn4gcFJEPm2gYERHFY2KO/AiAj6rq3SJyIoB9InKbqt5nYNtERBQh9SdyVT2kqnc7P/8GwP0AynEFgIioBozOkYvIFgCjAO7y+d0OEZkRkZmFhQWTuyUiqjVjgVxETgBwA4CPqOrT3t+r6h5VHVPVsaGhIVO7JSKqPSOBXESa6Abxa1V1r4ltEhFRPCayVgTA5wHcr6qfSd8kIiJKwsQn8m0A/hjAeSKy3/nvAgPbJSKiGFKnH6rqdwGEV6ghIqLM8M5OIiLLMZATEVmOgZyIyHIM5ERElmMgJyKyHAM5EZHlGMiJiCzHQE5EZDkGciIiyzGQExFZjoGciMhyJh71VitTs21cddNBLC51AAAnHd/ElReeDgCYnJ7H44tLeF6rCRHgqcMdNESwrIrhwRYmxkewfZQPTzJtara92vcbLO5n93H0xtDi4c7qMQFYc5xvfOkQ7nhgwdrjDjrepD+7+8f93hwQYEWB4Yi+iur37aPDoWOsDONPVDXXHQLA2NiYzszM5L7ftKZm25i4fg6dlbV9NiBAY0DQWQ7vy1azgasvPtOqN1vZTc22sWvvASx1lleX2djPfsfh1hwQQBA6xmw67qjjTao50P3AtBIznPX6CkBoO1rNBi45Zxg37Gv7jjG/12d5HkRkn6qOrVvOQB7ftt23o724lGobw4MtfG/neYZaREHnxLZ+NjG2AHuO29TxpjE82AKAyHb0vlUneX1W5yEokHNqJYHHDQw8E9ugo4L607Z+NtVeW467DO2M2wa/IB71+ryPjxc7E9jg/AUueht0VFB/2tbPptpry3GXoZ0bBlux2tEQ/8cthL0+7+NjIE9gYnykO1fpMSBAsxH9bI1Ws7F6UYbMmBgfQavZWLPMxn72Ow635oBEjjGbjjvqeJNqDgh83pqBen0V1Y5Ws4HLzt0UOMbKMv44tZJA7+IFs1bKo9efRWcNpOU9jqpnrYQdb95ZK0HtcK83dtrJoWOs6PHHi51ERJYIutjJqRUiIssxkBMRWY6BnIjIcgzkRESWYyAnIrIcAzkRkeWYR16AMlRLIypClcd+1LFleewM5DnzVn1rLy5h194DAFCZAU3kp8pjP+rYsj52Tq3kbHJ6fl3JzKXOMian5wtqEVE+qjz2o44t62OvxSfyMn2dq0q1PqKkqjz2o44t62M38olcRK4RkSdF5F4T2zOp95WmvbgExdGvNFOz7ULaU5ZqaUR5q/LYjzq2rI/d1NTKFwCcb2hbRpXt61xZqqUR5a3KYz/q2LI+diNTK6r6bRHZYmJbppXt61xVqvURJVXlsR91bFkfu7Hqh04g/4aqnhHw+x0AdgDA5s2bz3nkkUeM7DdKVR4FZqMyXZsgqoLCqx+q6h5VHVPVsaGhobx2W+mvc2VWtmsTRFVW+fTD7aPDuPriMzE82IKg+0nclieN26xs1yaIqqwW6YfbR4cZuHNWtmsTRFVmKv3wOgDfBzAiIo+JyOUmtkv2qnKqGVHZGAnkqnqZqp6qqk1V3aiqnzexXbIXr00Q5acWUyuUvyqnmhGVDQN5ClOz7TVP7T7p+CauvPB0BitHv9cm3GmL3qea956G3l5cggDoJc8e3xzAcc3Guqefp5UmhdLvtcDaJ7279cYPEPwHsMiUzt6+24tLaIhgWRXDGfZ171x7x0HQk+773U9QlULvGEv6/s66v9yM5ZEnMTY2pjMzM7nv16Sp2TYmrp9DZ2Vt/zUbgsl3n8Vg3idvlbh+tZqN1NlJfm2Ju12/1zYHum/mlZC33IAAjQFBZ/noSr19Aui7PWmFnZes+jquJPuPOqdR7Yj7/s6qvwrPI6+ayen5dUEcADrLyhS7FPzSFvthItUxTQql32s7K+FBHABWFGuCuHufRaZ0hp2XrPo6riT776dKoVvc93fW/eXFqZU+haXRMcWufyb7Lu220qRQmh4DRY+3qH1k1demX99vlcKk+8q6v7z4ibxPYWl0TLHrn8m+S7utNCmUpsfAhsFWoSmdUfvIqq9Nv77fKoVJ95V1f3nVKpBPzbaxbfft2LrzZmzbfXuq28UnxkfQHJB1y5sNYYpdCn5pi/0wkeqYJoXS77XNAYHPkFljQLpjyG+fRaZ0hp2XrPo6riT776dKoVvc93fW/eVVm6kV049a6r2GWStmedMWi8xaSZNCGfRaIF3WSr/tSct9PFlkYfj1VxZZK0mqFKbJWsm6v7xqk7XCKojZYZVDonwEZa3U5hM5a39ko8oP1CWyRW3myFn7IxusckhUvNoEctb+yAa/6RAVrzZTK34XH9yfHHt3dXGuN5kNgy3faw/8plNeHOfVU5uLnT1Bt+hecs4wbtjXXrO8d8U6qyvNVZDmNnbKH8+X3XiLviNoTve6ux5dt7z3J46PKQvGJzDZhdc0qqk2Uys9QXO3yxHfTHqDvd8AlfXX2bCKgWn3FVTFL87xJKkAx6/82Qsa/+3FJbziE7eu5rdH5eUnPVdVO7dB49qd+57ncdYukAfN6fZORph+L+BlnaLn3b77ZpO0+/Jr+8T1c4AcLe4UtA/va3v967c+0xjzETT+gbXj5nBnBYc7KwDWn4uk56pq5zZsXH/pzp+trpfncdZuaiUoe+WyczdF3iLc7wW8rL/ORlVsS7OvoCp+QRX64rbLuz6/8ufDb/xHVA0AEF0hMOxcVe3cJqnUmNdx1u4TedgtumOnnex7ay6QLlUx6xS9LKvxJXmdd90kFeCYxpgPv/Ef9AndK6pCoKnlZZe03XkcZ+0CORD85Jqs6iNknaIX583Y776SvNG9+4h6rXt9pjGaFzQv7R3/QeUrvNwVApOcq6qd2yTvid76Wavd1EqY3txX7yQtq65+Ek8zx5X1zUhRFdvS7Cuoil9Qhb647fKuzxu2zHKPZUV45lVQJU+3qAqBYeeqauc2SaXGvI6zlp/Ig4TN5aUJ5Fk/iDiqYmCafYVV8Ys6niTfcPiwZrOSjGW/Sp5hWStJz1XVzm3YuC4qa6V2NwSF2brzZvj1hgB4ePfb825O7sIefhsVwJOkl1UtFa2Mtuy8OfB3w4Mt9r2lal/9MI6qzeUl4Zci5k2lCko7nHnkV2vuig1Lu6paKloZTc22112s7xFgdYyz76uDc+QuVZvLSyJOSlVQ2qHfXbFBaVdVS0Uro8nped8gDqwP7uz7auAncpeqzeUlkSZFKuhGKr9tVi0VrYzKmB5H2WIg9whKTay6pClVbkF3xfpNSdV5+iovSe9eZt/bj1MrBCBeSlVQ2qHfXbFBU1J1nr7KS5K7l9n31cBP5AQg+uG3UVkrvbtio6ak6jx9lZc4dy+z76vFSPqhiJwP4O8ANAD8q6ruDlu/n/TDONX9skprS7PdqNdOzbbX5O+6n9TtrrAW92necdqaJs0wy74K2k7vfD91uJP4bluTYyJsW2Hn6u0vPxXfmDvke46zaGfaYwLW3pPw7JHl1QJacZ8k7x3XAwKsaLlq++ddMdTEMQelH6YO5CLSAPAjAG8B8BiAHwK4TFXvC3pN0kDuVwzfLejBECYK5qcpxB/12qnZNiaun0NnZe05aDYE73vlpnXH411n8t1nhVYb9GtrVF8C3SkUd5ph3GM29dCCOG2Ms22TD1EI2xaAWO11c5+/oh724Ldfv3Mf1vag7fqN654yPMgiTkzpt41Zns8sHyzxKgAPqupPVPVZAF8GcJGB7a6KU90vSQpc2n3H3W7Uayen530He2dZfY/Hu06caoNxqgyu23bM6oZeplIL41aXi9q2yVTHsG0lqYbX4z5/RaVkxq1s6eU39rzbDQriQDlSHvOuGJr1MZuYIx8G8Kjr348BONe7kojsALADADZv3pxoB3HSo5KkwJnYd5qKg1FV5IDoB134vT5OW9P0R5Jqhklel2b9sHVNpjpmkTbZbzVBU7IaC1lW4zSliIqhWR5zblkrqrpHVcdUdWxoaCjRa+OkRzXEv+hP2tSqsIpuaV8bto2g4wnbfpy2pumPqNem6at+1w9b11R7oraVprJk1LazlNVYSPPeyEuWbSzifJoI5G0Am1z/3ugsMyZOdb+sUqvSpMtFvTao6lyzIZEPumg2JFa1wThVBtdtO2Z1Qy9TqYVxq8tFbdtkqmPYtpJUw+txn7+iUjLjVrb08ht73u2GVVMsQ8pj3hVDsz5mE1MrPwTwEhHZim4AvxTAHxrY7qq41f2ySK1Kky4X9Vq/qnPurICgB10EZQ7EaWvaNMOs+ipsO/1mrZhMdYyzrX6zVopKyYxT2bKfrBW/cV22rJUiKoZmecym0g8vAPC36KYfXqOqfxO2flmrH9ZJWSoQlqUdVcY+ro5Mqx+q6jcBfNPEtih7ZalAWJZ2VBn7uB54i34NlaUCYVnaUWXs43pgIK+hslQgLEs7qox9XA+stVJDRVUg9M7VDh7fxFOHO7m3o06CzvXzWs0CWkNZ4SfyGioiPcrvYcDP/N+RvtIcKb6gVMD/ffaI74OYyU4M5DW0fXQYV198JoYHWxB0U8Kyrn0RdDv4c489Jtd21M320WGc8Jz1X7yjbrMnu1g9tRKUVpVlVTNT7TVZwTFuxcOgfHUTxxPV1qA52V8vdbD/yrf23YYk/Ko+RlUltEHUeVj0mb4CzM2Tuys/xsnztz0dsozttzaQB6VVeR8E3HuTutcB8k+98rbXr11JHmIctF2/1/hVo3vqcAcTX5sL3XaS44lqa9FPBop6uDSQvk+KEOc8ZNn33v33agQFjQfb0yHL2n5rp1aC0qqiqgYWlXqVVQXHuBUPg6os5lXhregnA8WtUGjblEOc85Bl34f1q994sD0dsqztt/YTedDXwn6qBuYhqwqOaSse5lXhregnA5mqqFg2cc5Dln2ftCKm7emQZW2/tYE86QNmva/Ne54rzsON+3k4bpyvzWH7TlPhLenX9SIfbJ3k4dI2pT/GPQ9Z9X1Uv/pV6LT54dtlbb+1UytJHjDrXeeNLx1alwq3a++BTNOxsqrgGLfiYVCVRZsqvKURt0Jhmj4pQtHnIaxf/dpRdHvTKmv7rf1EHvcBs37ZIUHzXB/9anYXurKq4Jik4qHJrJWip0qSCqr6aHvWStHnwb3/OFkrRbc3rbK230j1w6SKrn64defNCDrqMjxP0JR+Ug7jPGC4TAOYjkp6vnk+7ZNp9UPbhM3r9a5A2z6g+0k5DEutAlDKtCvqSnq+y5pGR/2xdo48jaj50qKvQJvQT8ph0gcMlyHtirqSnm+ez2qp5Sfy3ieOj351LnGWiC1MPpQ4i/RFMivpOSprGh31p5afyIFuMP/0e88q5RVoE0w+lDjsAcOm7g7ctvt2bN15M7btvp3FnPqQ9HwX9cBnykZtAzlQTPGovPSTcpj0AcMm/uj5VUXMOhW0ipKe77Km0VF/ajm14uZNJ+rNEdoezPtJOYz7gGGTWQ5hc7W2n4M8JT3fZU2jo/7UMv3QzXv1Hug/BTFtOlfS6ogmKjtmkYKWZJtBqaAC4OHdb+9r335Pbx+M6CtvvyZ5cnyd0/j8Kkre8cBCLfsiD0Hph7UP5Nt23+6bijg82ML3dp4Xeztp/yD4vd6t1WzgknOG11RH9FsnyR8gk3/E+t2mqf7v7dubghfE3aaovge6UxST7z4rMo3Pu+0qi9NvdemLvAQF8lrPkQPmrt6nTefqtzpiv/sL2mfaFLQiqyIGpeD5cbcpTmVEpvGtF6ff6tIXRat9IDd19T7tH4Q01RH72V/YumlS0PqpimjqgnPSdvfWT3OO6pzGZ3JsUzq1v9g5MT7i+9V4Ynwk0dxn2qpoaaoj9rO/sH2mSUErsipikgqH7jbFfV1QGl8Zq+HlIU2/kVm1/0Qe9IkQQKK0uLRTBP1WR+x3f0H7TJuCVmRaW1AKnh93m+JURmQa33px+q0ufVG02n8iB/w/EW7bfXuitLi06Vz9VEdMm7WSRQpakWltfil4cbJW/Po+btZKndP4gipKMmslf7XPWgliOi2OiCgtZq0kxFuYicgWDOQB6jz3SUR2SRXIReQ9InJQRFZEZN3HfZtVuQ4LEVVL2oud9wK4GMA/G2hL6RT5sOCqq/Nt7USmpQrkqno/AIjES/kiAvh0GiLTcpsjF5EdIjIjIjMLCwt57ZZKqM63tRNlIfITuYh8C8ALfH51hap+Pe6OVHUPgD1AN/0wdgupcup8WztRFiIDuaq+OY+GxBVUNrO9uLR6C/twxW9MsH1+uejb2m3vPyIvq9IP/Z4m86U7f7YaFHp1SNzLq/bUmSo8UafI1M4q9B+RV9r0w3eJyGMAXgPgZhGZNtMsf3HKZgapyhxsFeaXi0ztrEL/EXmlzVq5EcCNhtoSKe0cahXmYKsyv1xUamdV+o/IzaqplbRzqFW4vZ6lA9Jh/1EVWRXI45TNDFKV2+tZOiAd9h9VkVWB3G9u9Y9evRnDzqephnNjknt51W6vZ+mAdNh/VEUsY0tEZAmWsSUiqigGciIiyzGQExFZjoGciMhyDORERJZjICcislzaJwQRVUacqoi9ddqLSxAAveTdk45v4soLT2c+OhWCgZwI8Z5a5F3HfQfGU4c7mPja3Jr1ifLCqRUixKuKGFV9s7OsrKJIhWAgJ0K8qohxKiSyiiIVgYGcCPGqIsapkMgqilQEBnIixKuKGFV9s9kQVlGkQvBiJxGOXqAMy1pxr8OsFSoTVj8kIrIEqx8SEVUUAzkRkeUYyImILMdATkRkOQZyIiLLMZATEVmOgZyIyHIM5ERElmMgJyKyHAM5EZHlGMiJiCyXKpCLyKSIPCAi94jIjSIyaKhdREQUU9pP5LcBOENVXw7gRwB2pW8SERElkSqQq+qtqnrE+eedADambxIRESVhco78QwBuCfqliOwQkRkRmVlYWDC4WyKieot8sISIfAvAC3x+dYWqft1Z5woARwBcG7QdVd0DYA/QrUfeV2uJiGidyECuqm8O+72IfBDAOwC8SYt4SgURUc2letSbiJwP4OMA3qCqh800iYiIkkg7R/73AE4EcJuI7BeRzxloExERJZDqE7mqvthUQ4iIqD+pAjlRHUzNtjE5PY/HF5ewYbCFifERbB8dLrpZRKsYyIlCTM22sWvvASx1lgEA7cUl7Np7AAAYzKk0WGuFKMTk9PxqEO9Z6ixjcnq+oBYRrcdAThTi8cWlRMuJisBAThRiw2Ar0XKiIjCQE4WYGB9Bq9lYs6zVbGBifKSgFhGtx4udRCF6FzSZtUJlxkBOFGH76DADN5Uap1aIiCzHQE5EZDkGciIiyzGQExFZjoGciMhyUsSzIERkAcAjfb78FAC/MNgcU8raLqC8bWO7kilru4Dytq1q7TpNVYe8CwsJ5GmIyIyqjhXdDq+ytgsob9vYrmTK2i6gvG2rS7s4tUJEZDkGciIiy9kYyPcU3YAAZW0XUN62sV3JlLVdQHnbVot2WTdHTkREa9n4iZyIiFwYyImILGdVIBeR80VkXkQeFJGdBbZjk4jcISL3ichBEfmws/wqEWmLyH7nvwsKaNtPReSAs/8ZZ9nJInKbiPzY+f9JObdpxNUn+0XkaRH5SFH9JSLXiMiTInKva5lvH0nXZ50xd4+InJ1zuyZF5AFn3zeKyKCzfIuILLn67nM5tyvw3InILqe/5kVkPOd2fcXVpp+KyH5neZ79FRQfshtjqmrFfwAaAB4C8EIAxwKYA/CygtpyKoCznZ9PBPAjAC8DcBWAjxXcTz8FcIpn2acA7HR+3gngkwWfx58DOK2o/gLwBwDOBnBvVB8BuADALQAEwKsB3JVzu94K4Bjn50+62rXFvV4B/eV77pz3wRyA4wBsdd6zjbza5fn9pwH8VQH9FRQfMhtjNn0ifxWAB1X1J6r6LIAvA7ioiIao6iFVvdv5+TcA7gdQ5oLVFwH4ovPzFwFsL64peBOAh1S13zt7U1PVbwP4lWdxUB9dBODftOtOAIMicmpe7VLVW1X1iPPPOwFszGLfSdsV4iIAX1bV36rqwwAeRPe9m2u7REQAvBfAdVnsO0xIfMhsjNkUyIcBPOr692MoQfAUkS0ARgHc5Sz6c+fr0TV5T2E4FMCtIrJPRHY4y56vqoecn38O4PkFtKvnUqx9cxXdXz1BfVSmcfchdD+59WwVkVkR+R8ReX0B7fE7d2Xpr9cDeEJVf+xalnt/eeJDZmPMpkBeOiJyAoAbAHxEVZ8G8E8AXgTgFQAOofvVLm+vU9WzAbwNwJ+JyB+4f6nd73KF5JyKyLEA3gngemdRGfprnSL7KIiIXAHgCIBrnUWHAGxW1VEAfwngP0Tkd3JsUinPnctlWPuBIff+8okPq0yPMZsCeRvAJte/NzrLCiEiTXRP0rWquhcAVPUJVV1W1RUA/4KMvlKGUdW28/8nAdzotOGJ3lc15/9P5t0ux9sA3K2qTzhtLLy/XIL6qPBxJyIfBPAOAO93AgCcqYtfOj/vQ3cu+vfyalPIuStDfx0D4GIAX+kty7u//OIDMhxjNgXyHwJ4iYhsdT7ZXQrgpiIa4sy/fR7A/ar6Gddy97zWuwDc631txu16roic2PsZ3Qtl96LbTx9wVvsAgK/n2S6XNZ+Siu4vj6A+ugnAnziZBa8G8GvX1+PMicj5AD4O4J2qeti1fEhEGs7PLwTwEgA/ybFdQefuJgCXishxIrLVadcP8mqX480AHlDVx3oL8uyvoPiALMdYHldxDV4NvgDdK8APAbiiwHa8Dt2vRfcA2O/8dwGAfwdwwFl+E4BTc27XC9HNGJgDcLDXRwB+F8B/A/gxgG8BOLmAPnsugF8CeJ5rWSH9he4fk0MAOujOR14e1EfoZhL8gzPmDgAYy7ldD6I7f9obZ59z1r3EOcf7AdwN4MKc2xV47gBc4fTXPIC35dkuZ/kXAPypZ908+ysoPmQ2xniLPhGR5WyaWiEiIh8M5ERElmMgJyKyHAM5EZHlGMiJiCzHQE5EZDkGciIiy/0/C67Y2H2OWMcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(diff)), diff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPXUlEQVR4nO3cf6xkZX3H8fenbNn+0MACK25Z6KJs0qxpojhBTa0xFVagsWtbkkL/cNPSbNJKWmtMuoSkUPQPMFVaI7VSMaGkEaytcRNjtgj6T9Mgdy0qq+IuiGG3CMuPYoipFP32j3nWzN7OZe/dmb2zw/N+JZM553uemfOdhzPzuXPOLKkqJEn9+plZNyBJmi2DQJI6ZxBIUucMAknqnEEgSZ1bM+sGjsUZZ5xRmzZtmnUbkjRX9uzZ82RVrV9cn8sg2LRpEwsLC7NuQ5LmSpLvjat7akiSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHXOIJCkzhkEktQ5g0CSOjeVIEhycZIHk+xPsnPM9rVJ7mzb702yadH2c5I8l+R90+hHkrR8EwdBkpOAm4FLgC3AFUm2LBp2JfBMVZ0H3ATcuGj7h4EvTNqLJGnlpvGN4AJgf1U9XFXPA3cA2xaN2Qbc1pY/A7wtSQCSvBP4LrB3Cr1IklZoGkFwFvDoyPqBVhs7pqpeAJ4FTk/yMuAvgL862k6S7EiykGTh0KFDU2hbkgSzv1h8HXBTVT13tIFVdUtVDapqsH79+uPfmSR1Ys0UnuMgcPbI+sZWGzfmQJI1wCnAU8AbgMuSfBA4FfhJkv+pqo9OoS9J0jJMIwjuAzYnOZfhB/7lwO8vGrML2A78B3AZcE9VFfDrhwckuQ54zhCQpNU1cRBU1QtJrgJ2AycBn6yqvUmuBxaqahdwK3B7kv3A0wzDQpJ0AsjwD/P5MhgMamFhYdZtSNJcSbKnqgaL67O+WCxJmjGDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHXOIJCkzhkEktQ5g0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpc1MJgiQXJ3kwyf4kO8dsX5vkzrb93iSbWv2iJHuSfKPd/8Y0+pEkLd/EQZDkJOBm4BJgC3BFki2Lhl0JPFNV5wE3ATe2+pPAO6rqV4HtwO2T9iNJWplpfCO4ANhfVQ9X1fPAHcC2RWO2Abe15c8Ab0uSqvrPqvqvVt8L/HyStVPoSZK0TNMIgrOAR0fWD7Ta2DFV9QLwLHD6ojG/C3y1qn40hZ4kScu0ZtYNACR5DcPTRVtfZMwOYAfAOeecs0qdSdJL3zS+ERwEzh5Z39hqY8ckWQOcAjzV1jcCnwXeVVUPLbWTqrqlqgZVNVi/fv0U2pYkwXSC4D5gc5Jzk5wMXA7sWjRmF8OLwQCXAfdUVSU5Ffg8sLOq/n0KvUiSVmjiIGjn/K8CdgPfAj5dVXuTXJ/kt9qwW4HTk+wH3gsc/onpVcB5wF8mub/dXjFpT5Kk5UtVzbqHFRsMBrWwsDDrNiRpriTZU1WDxXX/ZbEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHXOIJCkzhkEktQ5g0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ1bM40nSXIx8LfAScAnquqGRdvXAv8IvB54Cvi9qnqkbbsauBL4MfCnVbV7Gj0ttmnn54/H00rSTDxyw29O7bkm/kaQ5CTgZuASYAtwRZIti4ZdCTxTVecBNwE3tsduAS4HXgNcDPxde76pMgQkvdRM83NtGqeGLgD2V9XDVfU8cAewbdGYbcBtbfkzwNuSpNXvqKofVdV3gf3t+SRJq2QaQXAW8OjI+oFWGzumql4AngVOX+ZjAUiyI8lCkoVDhw5NoW1JEszRxeKquqWqBlU1WL9+/azbkaSXjGkEwUHg7JH1ja02dkySNcApDC8aL+exkqTjaBpBcB+wOcm5SU5mePF316Ixu4Dtbfky4J6qqla/PMnaJOcCm4GvTKGnI0zz6roknQim+bk28c9Hq+qFJFcBuxn+fPSTVbU3yfXAQlXtAm4Fbk+yH3iaYVjQxn0a+CbwAvDuqvrxpD2NYxhI0ngZ/mE+XwaDQS0sLMy6DUmaK0n2VNVgcX1uLhZLko4Pg0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHXOIJCkzhkEktQ5g0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMTBUGS05LclWRfu1+3xLjtbcy+JNtb7ReSfD7Jt5PsTXLDJL1Iko7NpN8IdgJ3V9Vm4O62foQkpwHXAm8ALgCuHQmMv66qXwFeB/xakksm7EeStEKTBsE24La2fBvwzjFj3g7cVVVPV9UzwF3AxVX1w6r6EkBVPQ98Fdg4YT+SpBWaNAjOrKrH2vL3gTPHjDkLeHRk/UCr/VSSU4F3MPxWIUlaRWuONiDJF4FXjtl0zehKVVWSWmkDSdYAnwI+UlUPv8i4HcAOgHPOOWelu5EkLeGoQVBVFy61LcnjSTZU1WNJNgBPjBl2EHjryPpG4Msj67cA+6rqb47Sxy1tLIPBYMWBI0kab9JTQ7uA7W15O/C5MWN2A1uTrGsXibe2Gkk+AJwCvGfCPiRJx2jSILgBuCjJPuDCtk6SQZJPAFTV08D7gfva7fqqejrJRoanl7YAX01yf5I/mrAfSdIKpWr+zrIMBoNaWFiYdRuSNFeS7KmqweK6/7JYkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHXOIJCkzhkEktQ5g0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOTRQESU5LcleSfe1+3RLjtrcx+5JsH7N9V5IHJulFknRsJv1GsBO4u6o2A3e39SMkOQ24FngDcAFw7WhgJPkd4LkJ+5AkHaNJg2AbcFtbvg1455gxbwfuqqqnq+oZ4C7gYoAkLwPeC3xgwj4kScdo0iA4s6oea8vfB84cM+Ys4NGR9QOtBvB+4EPAD4+2oyQ7kiwkWTh06NAELUuSRq052oAkXwReOWbTNaMrVVVJark7TvJa4NVV9edJNh1tfFXdAtwCMBgMlr0fSdKLO2oQVNWFS21L8niSDVX1WJINwBNjhh0E3jqyvhH4MvAmYJDkkdbHK5J8uareiiRp1Ux6amgXcPhXQNuBz40ZsxvYmmRdu0i8FdhdVR+rql+qqk3Am4HvGAKStPomDYIbgIuS7AMubOskGST5BEBVPc3wWsB97XZ9q0mSTgCpmr/T7YPBoBYWFmbdhiTNlSR7qmqwuO6/LJakzhkEktQ5g0CSOmcQSFLnDAJJ6pxBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjpnEEhS5wwCSeqcQSBJnTMIJKlzBoEkdc4gkKTOGQSS1DmDQJI6ZxBIUucMAknqnEEgSZ0zCCSpcwaBJHUuVTXrHlYsySHge8f48DOAJ6fYzkuV87Q8ztPyOE/Lc7zn6Zerav3i4lwGwSSSLFTVYNZ9nOicp+VxnpbHeVqeWc2Tp4YkqXMGgSR1rscguGXWDcwJ52l5nKflcZ6WZybz1N01AknSkXr8RiBJGmEQSFLnugmCJBcneTDJ/iQ7Z93PaknySJJvJLk/yUKrnZbkriT72v26Vk+Sj7Q5+nqS80eeZ3sbvy/J9pH669vz72+Pzeq/ypVL8skkTyR5YKR23OdlqX2cqJaYp+uSHGzH1P1JLh3ZdnV7zQ8meftIfez7L8m5Se5t9TuTnNzqa9v6/rZ90yq95GOS5OwkX0ryzSR7k/xZq8/HMVVVL/kbcBLwEPAq4GTga8CWWfe1Sq/9EeCMRbUPAjvb8k7gxrZ8KfAFIMAbgXtb/TTg4Xa/ri2va9u+0samPfaSWb/mZc7LW4DzgQdWc16W2seJeltinq4D3jdm7Jb23loLnNvecye92PsP+DRweVv+e+CP2/KfAH/fli8H7pz1XBxlnjYA57fllwPfafMxF8fUzCdwlf4jvQnYPbJ+NXD1rPtapdf+CP8/CB4ENrTlDcCDbfnjwBWLxwFXAB8fqX+81TYA3x6pHzHuRL8BmxZ9wB33eVlqHyfybcw8Xcf4IDjifQXsbu+9se+/9oH2JLCm1X867vBj2/KaNi6znosVzNnngIvm5Zjq5dTQWcCjI+sHWq0HBfxbkj1JdrTamVX1WFv+PnBmW15qnl6sfmBMfV6txrwstY95c1U7pfHJkVMRK52n04H/rqoXFtWPeK62/dk2/oTXTmO9DriXOTmmegmCnr25qs4HLgHeneQtoxtr+GeEvyFeZDXmZY7n/mPAq4HXAo8BH5ppNyeQJC8D/gV4T1X9YHTbiXxM9RIEB4GzR9Y3ttpLXlUdbPdPAJ8FLgAeT7IBoN0/0YYvNU8vVt84pj6vVmNeltrH3Kiqx6vqx1X1E+AfGB5TsPJ5ego4NcmaRfUjnqttP6WNP2El+VmGIfBPVfWvrTwXx1QvQXAfsLn9QuFkhhefds24p+MuyS8mefnhZWAr8ADD13741wjbGZ7PpNXf1X7R8Ebg2faVczewNcm6dhpgK8NzuY8BP0jyxvYLhneNPNc8Wo15WWofc+Pwh07z2wyPKRi+tsvbL37OBTYzvMA59v3X/nr9EnBZe/ziOT88T5cB97TxJ6T23/lW4FtV9eGRTfNxTM36osoqXry5lOGV/IeAa2bdzyq95lcx/IXG14C9h183w3OtdwP7gC8Cp7V6gJvbHH0DGIw81x8C+9vtD0bqA4YfBA8BH2VOLugBn2J4WuN/GZ5vvXI15mWpfZyotyXm6fY2D19n+CG0YWT8Ne01P8jIL8iWev+1Y/Qrbf7+GVjb6j/X1ve37a+a9VwcZZ7ezPCUzNeB+9vt0nk5pvxfTEhS53o5NSRJWoJBIEmdMwgkqXMGgSR1ziCQpM4ZBJLUOYNAkjr3f2L2R5rvSOJDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# para\n",
    "p_p = paddle_model.state_dict()['fgcnn.recombine_layers.0.0.weight'].numpy().T\n",
    "t_p = torch_model.state_dict()['fgcnn_layer.recombine_layers.0.0.weight'].detach().numpy()\n",
    "diff_p = (p_p - t_p).flatten()\n",
    "print('max:', max(diff_p))\n",
    "plt.scatter(range(len(diff_p)), diff_p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/01/12 16:21:19] root INFO: logits: \n",
      "[2022/01/12 16:21:19] root INFO: \tmean diff: check passed: True, value: 1.7285346487483366e-08\n",
      "[2022/01/12 16:21:19] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "torch_model.eval()\n",
    "paddle_model.eval()\n",
    "torch_forward = []\n",
    "paddle_forward = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)\n",
    "    torch_forward.append(torch_out['y_pred'].detach().numpy())\n",
    "    # paddle\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    paddle_forward.append(paddle_out.numpy())\n",
    "\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(torch_forward))\n",
    "reprod_logger.save(\"step1/forward_torch.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(paddle_forward))\n",
    "reprod_logger.save(\"step1/forward_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"step1/forward_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"step1/forward_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/forward_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762831eace365ee16f120c22ed7d5689be70c5a8e9076c823f0ed1712f1c33fd"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('fuxictr_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
